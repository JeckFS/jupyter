{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T03:21:02.788517Z",
     "start_time": "2019-08-15T03:21:02.785188Z"
    }
   },
   "source": [
    "# 机器学习的四个分支"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#e41ec2' size=3>目的是学习样本到标签的映射关系</font><br>\n",
    "应用：<br>\n",
    "&emsp;&emsp;光学字符识别，语音识别，图像分类，语言翻译。<br>\n",
    "\n",
    "监督学习的领域范围：<br>\n",
    "1. 分类和回归\n",
    "2. <img src='images/1.png'/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 无标签\n",
    "* 用于数据可视化，数据压缩，数据去噪，更好理解数据中的相关性。\n",
    "* 常用方法：降维(dimensionality reduction)，聚类(clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 标签是使用启发式算法生成，而非人工设置。是一种无人工参与标记标签的监督学习。\n",
    "* 例子：<br>\n",
    "    1. 自编码器(autoencoder)\n",
    "    2. 时序监督学习(temporally supervised learning)，用未来的输入作为监督。<br>\n",
    "        如，给定视频中过去的帧来预测下一帧，或给定文本中前面的词来预测下一个词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**智能体(agent)**接收有关环境信息，并学会采取使某种奖励最大化的行动。<br>\n",
    "应用：<br>\n",
    "&emsp;&emsp;自动驾驶，机器人，资源管理，教育，游戏(如α狗)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**向量回归(vector regression)**：目标是一组连续值的任务。如预测图像边框。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 习得机器学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分数据集为训练集，验证集，测试集。<br>\n",
    "划分验证集的原因：<br>\n",
    "&emsp;&emsp;用于调节超参数(hyperparameter, 如层数，每层大小)，这个调节过程需要使用模型在验证集上的性能作为反馈信号。正是由于此，会导致模型在验证集上过拟合。每用验证集数据调节一次，模型就会习得一部分验证集的信息(信息泄露)。<br>\n",
    "若数据集很少可以使用留出验证，K折验证，带有打乱数据的重复K折验证。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单的留出验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于数据集比较大的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/2.png'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K折验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/3.png'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/4.png'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带有打乱数据的重复K折验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于数据集较少情况。另外在Kaggle中比较有用。<br>\n",
    "具体做法：<br>\n",
    "&emsp;&emsp;多次使用K折验证，在每次将数据划分为K个分区之前先将数据打乱。最终分数时每次K折验证分数的平均值。这种方法一共要训练和评估P*K个模型(P是重复次数)。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理，特征工程，特征学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "许多预处理和特征工程技术都是与特定领域相关的，本节只是介绍所有数据领域通用的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有神经网络的输入和目标都是浮点数张量(特定情况可以是整数张量)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 值标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 大部分特征值取值在[0,1]\n",
    "* 所有特征值的取值范围应大致相同\n",
    "* 每个特征值都标准化为平均值为0，标准差为1的数据<br>\n",
    "    x -= x.mean(axis=0)<br>\n",
    "    x /= x.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要特征值为0不代表特殊含义，对于缺失的数据都置为0是允许的。神经网络会顾略这个值。若测试集中有缺失值，那么训练集应该也要有缺失值，这样才能学到如何处理缺失值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征工程**：在将数据输入到神经网络之前，利用现有知识对数据进行硬编码的变换，使得更有利于神经网络学习。<img src='images/5.png'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过拟合和欠拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 如何防止过拟合？最优方法是获取更多的训练数据，次之是调节模型允许存储的信息量，或对模型允许存储的信息加以约束。如果一个网络只能记住几个模式，那么优化过程会迫使模型集中学习最重要的模式。这种降低过拟合的方法叫**正则化**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法1：减小网络大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型中参数的个数通常叫做模型的容量(capacity)。参数更多的模型拥有更大的记忆容量(memorization capacity)。因此训练时从较小的网络开始训练，逐渐增加层和层的大小，直到这种增加对验证损失的影响变得很小。容量大的模型收敛的更快(更容易过拟合)，但其泛化能力差的一批。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法2：添加权重正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单模型比复杂模型具有更好的泛化能力。简单模型是指：参数值分布的熵更小(或参数更少)的模型。 **权重正则化(weight regularization)**就是强制让模型参数取较小的值，从而限制模型的复杂度，这也使得权重值的分布更加规则(regular)。实现方法是向损失函数中添加与较大权重值相关的**成本(cost)**。\n",
    "* L1正则化\n",
    "* L2正则化(也叫权重衰减(weight decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向模型添加L2权重正则化\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras中不同的权重正则化项\n",
    "regularizers.l1(0.001)  # L1正则化\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)  # 同时做L1和L2正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法3：添加dropout正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每层的输出矩阵，以一定概率$p$(通常0.2~0.5)让矩阵元素变为0。最终的输出除以$p$。\n",
    "* 训练时按照概率p dropout，测试时最终结果乘以p\n",
    "* 训练时按照概率p dropout，输出时除以p，使得结果变大，这样测试时不用乘以p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习的通用工作流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义问题，收集数据集\n",
    "2. 选择衡量成功的标准\n",
    "    精度，准确率，召回率等\n",
    "3. 确定评估方法\n",
    "    留出验证集(数据量很大时)\n",
    "    K折交叉验证(验证集样本少时)\n",
    "    重复的K折验证(可用的数据(总的数据)较少)\n",
    "4. 准备数据\n",
    "5. 开发比基准更好的模型\n",
    "    <img src='images/6.png'/>\n",
    "6. 扩大模型规模：开发过拟合的模型\n",
    "7. 模型正则化与调节超参数\n",
    "    * 添加dropout\n",
    "    * 增加或减少层数\n",
    "    * 添加L1或L2正则化\n",
    "    * 尝试不同超参数(每层单元个数或优化器的学习率)\n",
    "    * (可选)反复做特征工程：添加新特征或删除没有信息量的特征\n",
    "    \n",
    "    \n",
    "每次使用验证过程的反馈来调节模型，都会将有关验证过程的信息泄露到模型中。重复次数不能太多。如果在测试集上的性能比验证集上的差很多，说明模型在验证集上出现过拟合。这时可以使用更可靠的评估方法，如重复的K折验证。    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
